{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creator\n",
    "* hiermit die h5py Files bauen und abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from cnn_utils import prep_data, create_dataset, load_dataset\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read addresses of each image, create labels, shuffle everything and split into train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create HDF-DataFile with empty arrays and labels in preparation for loading the images into it\n",
    "Takes as input a single path where all labeled images are stored. The label is extracted from their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths to positive/negative images\n",
    "input_path_neg = 'first_prototype/neg'\n",
    "input_path_pos = 'first_prototype/pos'\n",
    "\n",
    "# Anteile von train/val/test-set hier angeben. Derzeit wird allerdings nur Train/Test-set genutzt\n",
    "dataSplit = {\n",
    "    'train_split': 0.9,\n",
    "    'val_split': 0,\n",
    "    'test_split': 0.1}\n",
    "\n",
    "train_addrs, train_labels, test_addrs, test_labels = prep_data(input_path_neg,input_path_pos,dataSplit,shuffle_data = True, datatype = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the empty Arrays with image data and save a copy locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define where the function stores the hdf5 file\n",
    "#output_train_path = 'C:/Users/JansPC/AnacondaProjects/Weinseminar/wineModel/datasets/train_dataset.hdf5'\n",
    "#output_test_path = 'C:/Users/JansPC/AnacondaProjects/Weinseminar/wineModel/datasets/test_dataset.hdf5'\n",
    "\n",
    "output_train_path = 'datasets/train_128.hdf5'\n",
    "output_test_path = 'datasets/test_wenig.hdf5'\n",
    "\n",
    "pixel = {\n",
    "    \"width\": 128, \n",
    "    \"height\": 128}\n",
    "\n",
    "hdf5_train_file, hdf5_test_file = create_dataset(train_addrs, train_labels, test_addrs, test_labels, output_train_path, output_test_path, px = pixel, data_order = 'tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill HDF with images\n",
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 1000/1146\n"
     ]
    }
   ],
   "source": [
    "# a numpy array to save the mean of the images\n",
    "# mean = np.zeros(train_shape[1:], np.float32)\n",
    "\n",
    "# loop over train addresses\n",
    "for i in range(len(train_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Train data: {}/{}'.format(i, len(train_addrs)))\n",
    "\n",
    "    # read an image and resize accordingly\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = train_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (pixel['width'], pixel['height']), interpolation=cv2.INTER_CUBIC)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # add any image pre-processing here\n",
    "\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    #if data_order == 'th':\n",
    "    #    img = np.rollaxis(img, 2)\n",
    "\n",
    "    # save the image and calculate the mean so far\n",
    "    hdf5_train_file[\"train_set_x\"][i, ...] = img[None]\n",
    "    #mean += img / float(len(train_labels))\n",
    "\n",
    "# save the mean and close the hdf5 file\n",
    "#hdf5_file[\"train_mean\"][...] = mean\n",
    "hdf5_train_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over test addresses\n",
    "for i in range(len(test_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Test data: {}/{}'.format(i, len(test_addrs)))\n",
    "\n",
    "    # read an image and resize to (128, 128)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = test_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (pixel['width'], pixel['height']), interpolation=cv2.INTER_CUBIC)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # add any image pre-processing here\n",
    "\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    #if data_order == 'th':\n",
    "    #    img = np.rollaxis(img, 2)\n",
    "\n",
    "    # save the image\n",
    "    hdf5_test_file[\"test_set_x\"][i, ...] = img[None]\n",
    "\n",
    "# save the mean and close the hdf5 file\n",
    "#hdf5_file[\"train_mean\"][...] = mean\n",
    "hdf5_test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# loop1 over validation addresses\n",
    "for i in range(len(val_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print 'Validation data: {}/{}'.format(i, len(val_addrs))\n",
    "\n",
    "    # read an image and resize to (pixel, pixel)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = val_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (pixel, pixel), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # add any image pre-processing here\n",
    "\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "\n",
    "    # save the image\n",
    "    hdf5_file[\"val_img\"][i, ...] = img[None]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(input_path_neg, input_path_pos, dataSplit, shuffle_data = True, datatype = 'jpg'):\n",
    "    '''\n",
    "    macht die Vorarbeit für die create_dataset-function. Liest aus den negativ/positiv Ordnern die Bilder raus und erstellt\n",
    "    labels entsprechend. Teilt dann die Daten je nach Angabe in Trainings/Testdaten ein.\n",
    "\n",
    "    Argumente:\n",
    "        input_path_neg      -- Ordner, in dem Bilder der Klasse \"negativ\" liegen\n",
    "        input_path_neg      -- Ordner, in dem Bilder der Klasse \"positiv\" liegen\n",
    "        dataSplit       -- Dictionary, dass die Split-Anteile für Train/Val/Test Sets enthält\n",
    "        shuffle_data    -- shuffles the dataset if set on True.\n",
    "\n",
    "    Returns:\n",
    "        train_addrs     -- Pfade zu den einzelnen Bildern des trainingssets\n",
    "        train_labels    -- Array, das trainings labels enthält entsprechend der Reihenfolge in train_addr\n",
    "        test_addrs      -- Pfade zu den einzelnen Bildern des Testsets\n",
    "        test_labels     -- Array, das test labels enthält entsprechend der Reihenfolge in test_addr\n",
    "    '''\n",
    "\n",
    "    for path,i in input_path_neg,len(input_path_neg):\n",
    "        \n",
    "    \n",
    "    if datatype == 'jpg':\n",
    "        addrs_neg = glob.glob(input_path_neg + '/*.jpg')\n",
    "        addrs_pos = glob.glob(input_path_pos + '/*.jpg')\n",
    "\n",
    "    elif datatype == 'png':\n",
    "        addrs_neg = glob.glob(input_path_neg + '/*.png')\n",
    "        addrs_pos = glob.glob(input_path_pos + '/*.png')\n",
    "\n",
    "    labels_neg = [0 for addr in addrs_neg]\n",
    "    labels_pos = [1 for addr in addrs_pos]\n",
    "    \n",
    "    addrs = addrs_neg + addrs_pos\n",
    "    labels = labels_neg + labels_pos\n",
    "\n",
    "\n",
    "    if shuffle_data == True:\n",
    "        try:\n",
    "            c = list(zip(addrs, labels))\n",
    "            shuffle(c)\n",
    "            addrs, labels = zip(*c)\n",
    "        except ValueError:\n",
    "            print ('Es wurden keine labels ausgelesen! Höchstwahrscheinlich stimmt was nicht mit deiner Pfadangabe')\n",
    "            print ('das hier soll der Pfad zu den neg Bildertn sein' + str(addrs_neg))\n",
    "            print ('there are ' + str(len(addrs)) + ' adresses')\n",
    "            print ('there are ' + str(len(labels)) + ' labels')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
